[
  {
    "objectID": "posts/240508-nextflow-splitcsv/index.html",
    "href": "posts/240508-nextflow-splitcsv/index.html",
    "title": "Nextflow: using splitCsv() operator",
    "section": "",
    "text": "Introduction\nWhen I get *.fastq.gz files back for my Visium spatial libraries, spaceranger count command is used to generate various output files for QC metrics and downstream analysis. The command in my slurm job script looks like this:\n\nspaceranger count --id=18_57617_A1 --transcriptome=/home/skim823/projects/def-fdick/skim823/genomes/spacerange_hg38/refdata-gex-GRCh38-2020-A --probe-set=/home/skim823/projects/def-fdick/skim823/programs/spaceranger-2.1.1/probe_sets/Visium_Human_Transcriptome_Probe_Set_v2.0_GRCh38-2020-A.csv --fastqs=/scratch/skim823/visium/20240117_LH00244_0047_A22GM27LT3_Mura_Kim --sample=18_57617_A1_D1 --cytaimage=/scratch/skim823/visium/20240117_LH00244_0047_A22GM27LT3_Mura_Kim/etc/assay_CAVG10505_2023-12-06_10-13-34_V43L25-333_1701876913_CytAssist/CAVG10505_2023-12-06_10-35-13_2023-12-06_10-13-34_V43L25-333_D1_18-57617-A1.tif --image=/scratch/skim823/visium/20240117_LH00244_0047_A22GM27LT3_Mura_Kim/etc/tiff/18-57617-A1.tif --slide=V43L25-333 --area=D1 --loupe-alignment=/scratch/skim823/visium/20240117_LH00244_0047_A22GM27LT3_Mura_Kim/etc/json/18_57617_A1.json\n\nWith future samples, I want to use Nextflow to automate job submission.\n\n\nStrategy\nMy initial thought was to parse params.fastq, but --cytaimage, --image, --area, and --loupe-alignment arguments are no where to be found in these fastq files (unless I submit an ungodly sample name to the genomics core). Instead, I can provide a metadata.csv and use splitCsv() to store and consume all the required arguments.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nsample\ncytaimage\nimage\nslide\narea\njson\n\n\n\n\n18_57617_A1\n18_57617_A1_D1\netc/assay_CAVG10505_2023-12-06_10-13-34_V43L25-333_1701876913_CytAssist/CAVG10505_2023-12-06_10-35-13_2023-12-06_10-13-34_V43L25-333_D1_18-57617-A1.tif\netc/tiff/18-57617-A1.tif\nV43L25-333\nD1\netc/json/18_57617_A1.json\n\n\n20_24241_B2\n20_24241_B2_A1\netc/assay_CAVG10505_2023-12-06_10-13-34_V43L25-333_1701876913_CytAssist/CAVG10505_2023-12-06_10-35-13_2023-12-06_10-13-34_V43L25-333_A1_20-24241-B2.tif\netc/tiff/20-24241-B2.tif\nV43L25-333\nA1\netc/json/20_24241_B2.json\n\n\n\n\n\nIn the working directory, I have ${sample}_{S7,S8}_{L001,L002}_{R1,R2}_001.fastq.gz files. id and sample arguments in the .csv file must follow such format above. I think spaceranger is expecting some pre-determined fastq.gz read pairs across a couple of sequencing lanes.\netc/ is a subdirectory with CytAssist images, hi-res images, and alignment json files.\n\n\nNextflow\nThe full main.nf looks like this:\n\nnextflow.enable.dsl=2\nparams.csv = \"$projectDir/metadata.csv\"\nparams.transcriptome = \"/home/skim823/projects/def-fdick/skim823/genomes/spacerange_hg38/refdata-gex-GRCh38-2020-A\"\nparams.probeSet = \"/home/skim823/projects/def-fdick/skim823/programs/spaceranger-2.1.1/probe_sets/Visium_Human_Transcriptome_Probe_Set_v2.0_GRCh38-2020-A.csv\"\n\ncsv_ch = Channel\n            .fromPath(params.csv)\n            .splitCsv(header: true)\n            .map(\n                row -&gt; \n                tuple(row.id,\n                row.sample,\n                file (row.cytaimage),\n                file (row.image),\n                row.slide,\n                row.area,\n                file(row.json))\n            )\n\ntranscriptome_ch = Channel.fromPath(params.transcriptome)\nprobeSet_ch = Channel.fromPath(params.probeSet)\n\nprocess SPACECOUNT {\n    publishDir \"$projectDir/output\", mode: \"copy\"\n    cpus 32\n    memory 128.GB\n    time 2.h\n    clusterOptions '--account=def-muram'\n\n    input:\n    tuple val(id), val(sample), file (cytaimage), file (image), val(slide), val(area), file (json)\n    // setting directories as path() doesn't seem to work. It can't resolve relative paths. If I just use val(), I just have to express parameters as absolute paths in the script. \n    // path doesn't work but file does!\n    path transcriptome\n    path probeSet\n\n    output:\n    path \"$id/\"\n\n    script:\n    \"\"\"\n    spaceranger count --id $id  --fastqs $baseDir --sample $sample --cytaimage $cytaimage --image $image --slide $slide --area $area --loupe-alignment $json --transcriptome $transcriptome --probe-set $probeSet\n    \"\"\"\n}\n\nworkflow {\n    SPACECOUNT(csv_ch, transcriptome_ch.collect(), probeSet_ch.collect())\n}\n\n\n\n\n\n\n\nImportant\n\n\n\n\nwithin .map() (lines 9-18), must use file() instead of path() (error otherwise)\nline 34: must use file() for file paths instead of‚Ä¶ path() (no error, but the relative path does not resolve). I thought file() was DSL=1 lingo, but maybe not?\nreference\n\n\n\n\n\\ (‚Ä¢‚ó°‚Ä¢) /\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "posts/240115-shiny-pt1/index.html",
    "href": "posts/240115-shiny-pt1/index.html",
    "title": "Shiny app for data viz part 1",
    "section": "",
    "text": "I‚Äôm hosting a shiny app written in R on a cloud server. Its purpose is to allow users to interactively visualize spatial gene expression data from fibrosing interstitial lung disease patients. Such interactivity is useful here because there are too many possible logical comparisons between groups than what can reasonably fit in a manuscript.\nAt one point, I was losing track of how inputs were being processed into intermediate/final outputs. I wrote down a pen and paper version before, but it‚Äôs gotten even more complicated than that.\nNextflow introduced me to mermaid flowcharts. I wrote down the following on the live editor:\n\nflowchart\n    input$anno_type_select --&gt;|reactive| ROIs\n    ROIs --&gt; reactiveRun\n    input$run --&gt; |eventReactive| reactiveRun\n    reactiveRun --&gt; |renderUI| output$customization\n    output$customization --&gt; |reactive| pcaPlot\n    reactiveRun --&gt; |eventReactive| contrast\n    contrast --&gt; |reactive| efit\n    input$lfc --&gt; |reactive| lfc\n    lfc --&gt; |reactive| topTableDF\n    efit --&gt; |reactive| topTableDF\n    contrast --&gt; |reactive| topTableDF\n    topTableDF --&gt; |downloadHandler| output$downloadTable\n    topTableDF --&gt; |renderUI| output$table\n    efit --&gt; |reactive| volcano\n    contrast --&gt; |reactive| plotHeight\n    plotHeight --&gt; |reactive| volcano\n    contrast --&gt; |reactive| volcano\n    reactiveRun --&gt; |eventReactive| spe_ruv_subset\n    spe_ruv_subset --&gt; |eventReactive| pca_ruv_results_subset\n    spe_ruv_subset --&gt; |reactive| pcaPlot\n    input$shapes_n --&gt; |reactive| pcaPlot\n    input$colours_n --&gt; |reactive| pcaPlot\n    pca_ruv_results_subset --&gt; |reactive| pcaPlot\n    pcaPlot --&gt; |renderUI| output$pca\n    pcaPlot --&gt; |downloadHandler| output$downloadPCA \n    input$toggle_PCAcustom --&gt; |observeEvent| toggle::PCAcustom\n    toggle::PCAcustom --&gt; |uiOutput| output$customization\n    input$shapes_n --&gt; |renderUI| output$customization\n    input$colours_n --&gt; |renderUI| output$customization\n    input$toggle_customRange --&gt; |observeEvent| toggle::show_customRange\n    toggle::show_customRange --&gt; |uiOutput| output$customRange\n    input$customX --&gt; |renderUI| output$customRange \n    input$customY --&gt; |renderUI| output$customRange\n    input$customX --&gt; |reactive| customX\n    input$customY --&gt; |reactive| customY\n    customY --&gt; |reactive| volcano\n    customX --&gt; |reactive| volcano\n    input$maxOverlap --&gt; |reactive| maxOverlap\n    maxOverlap --&gt; |reactive| volcano\n    volcano --&gt; |reactive| volcanoPlots\n    volcano --&gt; |renderUI| output$volcanoUI\n    volcanoPlots --&gt; |downloadHandler| output$downloadVolcano\n    input$top_n_genes --&gt; |reactive| top_n_genes\n    input$heatmap_col --&gt; |reactive| heatmap_col\n    input$heatmap_range --&gt; |reactive| heatmap_range\n    input$heatmap_size --&gt; |reactive| heatmap_size\n    input$heatmap_fontsize --&gt; |reactive| heatmap_fontsize \n    reactiveRun --&gt; |reactive| lcpm_subset_scale\n    spe_ruv_subset --&gt; |reactive| lcpm_subset_scale\n    reactiveRun --&gt; |reactive| colnames4heatmap\n    spe_ruv_subset --&gt; |reactive| colnames4heatmap\n    colnames4heatmap --&gt; |reactive| heatmap\n    lcpm_subset_scale --&gt; |reactive| lcpm_subset_scale_topGenes\n    topTableDF --&gt; |reactive| lcpm_subset_scale_topGenes\n    top_n_genes --&gt; |reactive| lcpm_subset_scale_topGenes\n    heatmap_range --&gt; |reactive| heatmap\n    heatmap_col --&gt;  |reactive| heatmap\n    heatmap_fontsize --&gt;  |reactive| heatmap\n    heatmap_size --&gt; |reactive| heatmap\n    lcpm_subset_scale_topGenes --&gt;  |reactive| heatmap\n    heatmap --&gt; |renderUI| output$heatmapUI\n    lcpm_subset_scale_topGenes --&gt; |downloadHandler| output$downloadHeatmap\n    heatmap --&gt; |downloadHandler| output$downloadHeatmap\n\n\n\n\nflowchart\n    input$anno_type_select --&gt;|reactive| ROIs\n    ROIs --&gt; reactiveRun\n    input$run --&gt; |eventReactive| reactiveRun\n    reactiveRun --&gt; |renderUI| output$customization\n    output$customization --&gt; |reactive| pcaPlot\n    reactiveRun --&gt; |eventReactive| contrast\n    contrast --&gt; |reactive| efit\n    input$lfc --&gt; |reactive| lfc\n    lfc --&gt; |reactive| topTableDF\n    efit --&gt; |reactive| topTableDF\n    contrast --&gt; |reactive| topTableDF\n    topTableDF --&gt; |downloadHandler| output$downloadTable\n    topTableDF --&gt; |renderUI| output$table\n    efit --&gt; |reactive| volcano\n    contrast --&gt; |reactive| plotHeight\n    plotHeight --&gt; |reactive| volcano\n    contrast --&gt; |reactive| volcano\n    reactiveRun --&gt; |eventReactive| spe_ruv_subset\n    spe_ruv_subset --&gt; |eventReactive| pca_ruv_results_subset\n    spe_ruv_subset --&gt; |reactive| pcaPlot\n    input$shapes_n --&gt; |reactive| pcaPlot\n    input$colours_n --&gt; |reactive| pcaPlot\n    pca_ruv_results_subset --&gt; |reactive| pcaPlot\n    pcaPlot --&gt; |renderUI| output$pca\n    pcaPlot --&gt; |downloadHandler| output$downloadPCA \n    input$toggle_PCAcustom --&gt; |observeEvent| toggle::PCAcustom\n    toggle::PCAcustom --&gt; |uiOutput| output$customization\n    input$shapes_n --&gt; |renderUI| output$customization\n    input$colours_n --&gt; |renderUI| output$customization\n    input$toggle_customRange --&gt; |observeEvent| toggle::show_customRange\n    toggle::show_customRange --&gt; |uiOutput| output$customRange\n    input$customX --&gt; |renderUI| output$customRange \n    input$customY --&gt; |renderUI| output$customRange\n    input$customX --&gt; |reactive| customX\n    input$customY --&gt; |reactive| customY\n    customY --&gt; |reactive| volcano\n    customX --&gt; |reactive| volcano\n    input$maxOverlap --&gt; |reactive| maxOverlap\n    maxOverlap --&gt; |reactive| volcano\n    volcano --&gt; |reactive| volcanoPlots\n    volcano --&gt; |renderUI| output$volcanoUI\n    volcanoPlots --&gt; |downloadHandler| output$downloadVolcano\n    input$top_n_genes --&gt; |reactive| top_n_genes\n    input$heatmap_col --&gt; |reactive| heatmap_col\n    input$heatmap_range --&gt; |reactive| heatmap_range\n    input$heatmap_size --&gt; |reactive| heatmap_size\n    input$heatmap_fontsize --&gt; |reactive| heatmap_fontsize \n    reactiveRun --&gt; |reactive| lcpm_subset_scale\n    spe_ruv_subset --&gt; |reactive| lcpm_subset_scale\n    reactiveRun --&gt; |reactive| colnames4heatmap\n    spe_ruv_subset --&gt; |reactive| colnames4heatmap\n    colnames4heatmap --&gt; |reactive| heatmap\n    lcpm_subset_scale --&gt; |reactive| lcpm_subset_scale_topGenes\n    topTableDF --&gt; |reactive| lcpm_subset_scale_topGenes\n    top_n_genes --&gt; |reactive| lcpm_subset_scale_topGenes\n    heatmap_range --&gt; |reactive| heatmap\n    heatmap_col --&gt;  |reactive| heatmap\n    heatmap_fontsize --&gt;  |reactive| heatmap\n    heatmap_size --&gt; |reactive| heatmap\n    lcpm_subset_scale_topGenes --&gt;  |reactive| heatmap\n    heatmap --&gt; |renderUI| output$heatmapUI\n    lcpm_subset_scale_topGenes --&gt; |downloadHandler| output$downloadHeatmap\n    heatmap --&gt; |downloadHandler| output$downloadHeatmap\n\n\n\n\n\n\nNodes represent input, data and/or output variables. Curves represent reactive expressions or rendering functions.\nSome takeaways:\n\nthe whole thing really depends on input$anno_type_select and input$run, which are user-selected biological groups and pressing run, respectively\nvisual outputs (PCA, table, volcano, or heatmap) are created using renderUI while their downloadable counterparts are created using downloadHandler\n\nI don‚Äôt think whatever has been renderUI-ed can be converted into downloadable image files\n\nmostly straightforward except for toggle::*\n\nthese open customization panels that are not enabled by default\nif enabled, they have to take additional input from users\ninput through input$toggle_* activates toggle::*\nthis activates output$* through uiOutput\n\nsince this is an output, this is shown to users\n\ninputs are baked into these outputs!!\nreactive expressions take these inputs downstream\n\nflowchart is written by hand, so there can be some mistakes and omissions\n\nbut, writing it out could be helpful for really getting down to the nitty-gritty of what is exactly happening\nis there a package that can automatically generate a flowchart?\n\n\nThere are many other things that I could document about this app. Hosting it online for free through the Digital Alliance of Canada‚Äôs cloud was a bit of a journey. The how and why might be the topic for a part 2. In a part 3, I might document some cute tricks in R to process data with reactivity.\nYou can find the entire app‚Äôs code here. The raw and processed data underpinning the app are under embargo at this time.\n\n\\ (‚Ä¢‚ó°‚Ä¢) /\n\n\n\n\n Back to top"
  },
  {
    "objectID": "posts/2301106-rnaseq/index.html",
    "href": "posts/2301106-rnaseq/index.html",
    "title": "A primer on RNA-seq analysis",
    "section": "",
    "text": "Above diagram from Emmert-Streib, Moutari, and Dehmer (2016) nicely depicts how ‚Äúdata science‚Äù takes a combination of three kinds of disciplines. It can be a bit daunting to expand our expertise away from our home vertex. I was fortunate to be in a great training environment: my supervisor and the Howard Hughes Medical Institute sponsored me to attend the advanced sequencing technolgies/bioinformatics course at Cold Spring Harbor Labs, and senior graduate students organized bioinformatics workshops. It‚Äôs not that these two taught me everything I know about bioinformatics now; they got the ball rolling in a really good direction.\nSo I guess I should pay it forward. To whom? I‚Äôm not sure. I threw some stuff on RNA-seq together in 2023 for trainees on the 4th floor VRL‚Äîa pilot run, and attendance took a nose dive after the second week. A big problem (among many others) was copying and pasting my code from Powerpoint text boxes. Sometimes there would be a new line character error. Since then, I learned about HTML slides with xaringan or Quarto revealjs that have native code block support ü•≥.\nLinks to my slides are on my github pages1. The goal of this series is to demonstrate a RNA-seq workflow from Illumina reads to plots (PCA, Volcano, heatmap). At the time of writing, there are three weeks (one hour session each) worth of material. Week 1 slides are shown below as a teaser.\nView slides in full screen"
  },
  {
    "objectID": "posts/2301106-rnaseq/index.html#footnotes",
    "href": "posts/2301106-rnaseq/index.html#footnotes",
    "title": "A primer on RNA-seq analysis",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI think this is a cute hack because a repo is meant to host just one presentation. But I wanted to have all slides in one repo. In the docs directory in the top directory of my repo, I made a Quarto website (qmd) rendered to html. I got rid of the default index.html that just redirects to the slides. Github pages serves this html instead of redirecting. I tried to add a _quarto.yml to this index file, but it seemed to destroy the rendering.‚Ü©Ô∏é\nembedio extension used to embed these slides‚Ü©Ô∏é"
  },
  {
    "objectID": "about/index.html",
    "href": "about/index.html",
    "title": "About",
    "section": "",
    "text": "I‚Äôm Joon.\n\n\n\nI trained under Dr.¬†Fred Dick at Western University throughout my undergrad and graduate degrees. We did some interesting work, involving a new mouse strain (created in-house with CRISPR-Cas9), epigenetic silencing of repetitive elements and viral mimicry. Currently, I am looking to profile spatially resolved transcriptomes in fibrosing interstitial lung diseases with Dr.¬†Marco Mura also at Western."
  },
  {
    "objectID": "about/index.html#about-me",
    "href": "about/index.html#about-me",
    "title": "About",
    "section": "",
    "text": "I‚Äôm Joon.\n\n\n\nI trained under Dr.¬†Fred Dick at Western University throughout my undergrad and graduate degrees. We did some interesting work, involving a new mouse strain (created in-house with CRISPR-Cas9), epigenetic silencing of repetitive elements and viral mimicry. Currently, I am looking to profile spatially resolved transcriptomes in fibrosing interstitial lung diseases with Dr.¬†Marco Mura also at Western."
  },
  {
    "objectID": "about/index.html#more-about-me",
    "href": "about/index.html#more-about-me",
    "title": "About",
    "section": "More about me",
    "text": "More about me\nDespite being Korean, I have both first and middle names: Seung and June. It should really be Seungjune, all first name and no middle name. Something to do with a mistake on my first passport application. ‚ÄòSeung‚Äô part is challenging. It‚Äôs supposed to be as such: . I could have gone with my legal middle name, but my seventh grade self was keen on not being awkwardly misgendered."
  },
  {
    "objectID": "about/index.html#purpose-of-this-blog",
    "href": "about/index.html#purpose-of-this-blog",
    "title": "About",
    "section": "Purpose of this blog",
    "text": "Purpose of this blog\nI find myself going back to my old code to find some key snippets that I cannot recall. Or it‚Äôs some one-off trick that I couldn‚Äôt possible retain. It‚Äôs a bit of a dumpster dive every time. I hope writing it down here will help me retrieve those easier. This kind of format is apparently called a ‚Äúdigital garden‚Äù. The outlook for this blog does not look good given my experience with gardening.\nThere are some coding ‚Äúprojects‚Äù in planning/dev phase that I wouldn‚Äôt be able to digitally document otherwise."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "blog",
    "section": "",
    "text": "Nextflow: using splitCsv() operator\n\n\n\n\n\n\nnextflow\n\n\n\na tech tip to future self\n\n\n\n\n\nMay 8, 2024\n\n\njk\n\n\n\n\n\n\n\n\n\n\n\n\nShiny app for data viz part 2\n\n\n\n\n\n\nR\n\n\nshiny\n\n\ndata visualization\n\n\n\nhosting a shiny app on the web\n\n\n\n\n\nMar 22, 2024\n\n\njk\n\n\n\n\n\n\n\n\n\n\n\n\nShiny app for data viz part 1\n\n\n\n\n\n\nR\n\n\nshiny\n\n\ndata visualization\n\n\n\nunderstanding the flow between inputs, variables and outputs\n\n\n\n\n\nJan 15, 2024\n\n\njk\n\n\n\n\n\n\n\n\n\n\n\n\nA primer on RNA-seq analysis\n\n\n\n\n\n\nR\n\n\nRNA-seq\n\n\nHPC\n\n\nrevealjs\n\n\ndata visualization\n\n\n\nworkshop material\n\n\n\n\n\nNov 6, 2023\n\n\njk\n\n\n\n\n\n\n\n\n\n\n\n\nFirst blog\n\n\n\n\n\n\nnews\n\n\n\nhi there\n\n\n\n\n\nMay 8, 2023\n\n\njk\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "posts/230508-first-blog/index.html",
    "href": "posts/230508-first-blog/index.html",
    "title": "First blog",
    "section": "",
    "text": "After hemming and hawing on whether to create a blog and which tool to use, here is my first post üòÑ.\nI‚Äôve been finding the following blogs particularly useful: Aster Hu, Drew Dimmery, and Danielle Navarro.\nI‚Äôve decided to use Quarto because it seems to be more dynamic than Jekyll (as far as my understanding goes). Syntax highlighting for bash, groovy and R in expandable, copy-able code chunks will be nice for various scripts that I want to post eventually.\nI think my first project will be to write my CV using an rmarkdown template and share it as a pdf. This blog + CV[^1] will meet the minimum requirement for publication on Github pages.\n\n\\ (‚Ä¢‚ó°‚Ä¢) /\n\n\n\n\n Back to top"
  },
  {
    "objectID": "posts/240322-shiny-pt2/index.html",
    "href": "posts/240322-shiny-pt2/index.html",
    "title": "Shiny app for data viz part 2",
    "section": "",
    "text": "Rationale\nHere is the first part to this series.\nOnce I had a production version of my app (to be discussed in part 3 like a movie prequel), I wanted to make it accessible. What exactly is the point if I‚Äôm the only one using it in my bedroom? Close to nada. So, it got me thinking about deployment options. My self-imposed requirement was that it couldn‚Äôt cost me or the lab any money.\n\n\nOption 1\nThe first option I tried was publishing on shinyapps.io. This initially failed because their server did not have some dependency installed. I chimed in on this issue, promptly gave up, and looked for other options. I only recently made my first PR that was able to fix this. Now the app is successfully published, but it crashes as soon as I do anything with it. I think it‚Äôs due to lack of memory (1GB) with my free tier account. To get a custom URL and more performance, it‚Äôs going to cost cool $349/month üôÉ. On to the next option.\n\n\nOption 2\nSome institutions like Waterloo and Toronto seem to host shiny apps for free. Not Western or LHSC üò≠. On to the next option.\n\n\nOption 3\nI could make a docker image that users can download and run locally. But I thought this still might be a barrier to some, so I ruled it out.\n\n\nThe last resort\nThe Digital Alliance of Canada offers free virtual machines to those eager beavers. A VM can run shiny server that persistently hosts my app.\n\n1. Cloud setup\nCreating and accessing a new VM is covered thoroughly here. Through trial and error, I learned that my instance(s) must have at least 4GB of memory and 20GB of volume size.\n\n\n2. Shiny server\nShiny Server can be installed following this guide.\n\n\n\n\n\n\nImportant\n\n\n\nAll the R libraries that the app uses must be installed (sudo R to enable write permission).\nThose R libraries in turn depend on Linux packages that needs to be installed too.\n\nI don‚Äôt know if there is a way to know what these dependencies are in advance\n\nmaybe have to test out the app in a local shiny server running on Linux (through WSL perhaps)\n\nI just had to look at the error log (saved to /var/log/shiny-server/*.log) and painstakingly install missing packages with sudo apt-get install\n\n\n\n/etc/shiny-server/shiny-server.conf looks like this:\n# Instruct Shiny Server to run applications as the user \"shiny\"\nrun_as ubuntu;\n\n# Define a server that listens on port 3838\nserver {\n  listen 3838;\n\n  # Define a location at the base URL\n  location / {\n\n    # Host the directory of Shiny Apps stored in this directory\n    # site_dir /srv/shiny-server;\n    site_dir /home/ubuntu/ild-shiny-app;\n    # Log all Shiny output to files in this directory\n    log_dir /var/log/shiny-server;\n\n    # When a user visits the base URL rather than a particular application,\n    # an index of the applications available in this directory will be shown.\n    directory_index on;\n  }\n}\n\nMy app is hosted on localhost:3838 (root URL).\n/home/ubuntu/ild-shiny-app is where I cloned my git repo of the shiny app.\n\n\n\n3. nginx reverse proxy\nWhile Shiny Sever is hosting the app locally, nginx takes HTTP/HTTPS traffic to the local URL and back. This seems like what a reverse proxy is. More detail here and here. I also set up two worker nodes downstream of a load balancer.\nAfter the smoke cleared and the dust settled, this is my /etc/nginx/nginx.conf file:\nuser www-data;\nworker_processes auto;\npid /run/nginx.pid;\ninclude /etc/nginx/modules-enabled/*.conf;\n\nevents {\n        worker_connections 768;\n        # multi_accept on;\n}\n\nhttp {\n     log_format  main_ext  '$remote_addr - $remote_user [$time_local] \"$request\" '\n                      '$status $body_bytes_sent \"$http_referer\" '\n                      '\"$http_user_agent\" \"$http_x_forwarded_for\" '\n                      '\"$host\" sn=\"$server_name\" '\n                      'rt=$request_time '\n                      'ua=\"$upstream_addr\" us=\"$upstream_status\" '\n                      'ut=\"$upstream_response_time\" ul=\"$upstream_response_length\" '\n                      'cs=$upstream_cache_status' ;\n     upstream backend {\n                      ip_hash;\n                      server    172.16.111.219;\n                      server    172.16.111.150;\n                      server    localhost;\n     }\n\n\n     map $http_upgrade $connection_upgrade {\n          default upgrade;\n          ''      close;\n     }\n     include /etc/nginx/mime.types;\n     server {\n            server_name fibrosingild.com;\n            server_name www.fibrosingild.com;\n\n\n            location / {\n                        proxy_pass http://localhost:3838;\n                        proxy_redirect / $scheme://$http_host/;\n                        proxy_http_version 1.1;\n                        proxy_set_header Upgrade $http_upgrade;\n                        proxy_set_header Connection $connection_upgrade;\n                        proxy_set_header Host $http_host;\n                        proxy_read_timeout 20d;\n                        proxy_buffering off;\n            }\n\n\n    listen 443 ssl; # managed by Certbot\n    ssl_certificate /etc/letsencrypt/live/fibrosingild.com/fullchain.pem; # managed by Certbot\n    ssl_certificate_key /etc/letsencrypt/live/fibrosingild.com/privkey.pem; # managed by Certbot\n    include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot\n    ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot\n\n\n}\n\n    ##\n    # Basic Settings\n    ##\n\n    sendfile on;\n    tcp_nopush on;\n    types_hash_max_size 2048;\n    # server_tokens off;\n\n    # server_names_hash_bucket_size 64;\n    # server_name_in_redirect off;\n\n    include /etc/nginx/mime.types;\n    default_type application/octet-stream;\n\n    ##\n    # SSL Settings\n    ##\n\n    ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3; # Dropping SSLv3, ref: POODLE\n    ssl_prefer_server_ciphers on;\n\n    ##\n    # Logging Settings\n    ##\n\n    access_log /var/log/nginx/access.log main_ext;\n    error_log /var/log/nginx/error.log warn;\n\n    ##\n    # Gzip Settings\n    ##\n\n    gzip on;\n\n    # gzip_vary on;\n    # gzip_proxied any;\n    # gzip_comp_level 6;\n    # gzip_buffers 16 8k;\n    # gzip_http_version 1.1;\n    # gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript;\n\n    ##\n    # Virtual Host Configs\n    ##\n\n    include /etc/nginx/conf.d/*.conf;\n    include /etc/nginx/sites-enabled/*;\n\n    server {\n            if ($host = www.fibrosingild.com) {\n                return 301 https://$host$request_uri;\n                                          } # managed by Certbot\n    }\n}\nlines 11-19: - collects logging information for NGINX Amplify (health checks)\nlines 20-25: - sends HTTP requests to downstream worker nodes at those floating IPs\nline 34: - my custom domain name\nlines 37-46: - reverse proxy\nSSL: - all lines with #managed by Certbot was auto-generated with Certbot - this enables HTTPS for free\n\n\\ (‚Ä¢‚ó°‚Ä¢) /\n\n\n\n\n\n\n Back to top"
  }
]